# Projeto Tech Chalenge Fase-2
---
## üìå √çndice

- [üìù Sobre o Projeto](#-sobre-o-projeto)
- [üõ† Tecnologias e Ferramentas](#-tecnologias-e-ferramentas-utilizadas)
- [üß± Arquitetura da Solu√ß√£o](#-arquitetura-da-solucao)
- [üöÄ Como Configurar e Executar o Projeto](#como-Configurar-e-Executar-o-Projeto)
- [üìñ Cat√°logo de Dados e Metadados](#Cat√°logo-de-Dados-e-Metadados)
- [üóÇÔ∏è Estrutura de diretorios](#Estrutura-de-diretorios)
- [üé• V√≠deo Demonstrativo](#-v√≠deo-demonstrativo)
- [ü§ù Desenvolvedores](#-desenvolvedores)
- [‚öñÔ∏è Licen√ßa](#-Licen√ßa)
---


## üìù Sobre o Projeto
Este reposit√≥rio cont√©m a implementa√ß√£o do `Tech Challenge Fase 2 da P√≥s-Gradua√ß√£o em Machine Learning`, focado na constru√ß√£o de um pipeline de dados completo para ingest√£o, processamento e an√°lise de dados do preg√£o da **B3 (Bovespa)**. A arquitetura √© totalmente serverless, utilizando servi√ßos AWS como `S3`, `Glue`, `Lambda` e `Athena`, seguindo as melhores pr√°ticas de Big Data.

O projeto aborda o desafio de extrair dados financeiros de uma fonte externa, transform√°-los em um formato otimizado para an√°lise e disponibiliz√°-los para consultas eficientes, garantindo escalabilidade, resili√™ncia e custo-benef√≠cio.

### ‚ú® Funcionalidades e Requisitos Implementados
O pipeline de dados foi desenvolvido para atender aos seguintes requisitos obrigat√≥rios:

- **Extra√ß√£o de Dados (Scraping):** Realiza o scraping de dados do preg√£o do site oficial da B3.

- **Ingest√£o na Camada Raw:** Os dados brutos s√£o ingeridos no Amazon S3 em formato Parquet, com particionamento di√°rio para otimiza√ß√£o de consultas.

- **Orquestra√ß√£o com Lambda:** Um evento no S3 (ao adicionar novos dados brutos) aciona uma fun√ß√£o AWS Lambda.

- **Disparo de Job ETL (Glue):** A fun√ß√£o Lambda (desenvolvida em Python) √© respons√°vel por iniciar um job de ETL (Extract, Transform, Load) no AWS Glue.

    - **Transforma√ß√µes no AWS Glue:** O job Glue, configurado visualmente, executa as seguintes transforma√ß√µes obrigat√≥rias:

        - **Agrupamento e Sumariza√ß√£o:** Realiza agrupamentos num√©ricos com sumariza√ß√£o, contagem ou soma.

        - **Renomea√ß√£o de Colunas:** Renomeia duas colunas existentes, al√©m das colunas de agrupamento.

        - **C√°lculo com Datas:** Executa um c√°lculo envolvendo campos de data (ex: dura√ß√£o, compara√ß√£o, diferen√ßa entre datas).

    - **Armazenamento na Camada Refined:** Os dados processados e refinados pelo job Glue s√£o salvos no S3 em formato **Parquet**, em uma pasta `refined`, particionados por data e pelo nome/abrevia√ß√£o da a√ß√£o do preg√£o.

    - **Cataloga√ß√£o Autom√°tica (Glue Catalog):** O job Glue cataloga automaticamente os dados no AWS Glue Data Catalog, criando uma tabela no banco de dados padr√£o.

- **Disponibilidade no Athena:** Os dados refinados est√£o dispon√≠veis e leg√≠veis para consultas no Amazon Athena.

## üõ† Tecnologias e Ferramentas
|Ferramenta| Categoria| Utiliza√ß√£o no Projeto|
|----------|----------|----------|
|üêç Python 3.13         | Linguagem de Programa√ß√£o |Linguagem principal para as fun√ß√µes Lambda e o script PySpark.|
|‚ú® PySpark Framework   | Framework de Processamento de Dados |utilizado no AWS Glue para processamento distribu√≠do dos dados.|
|üêë AWS Lambda          | Servi√ßo AWS |Orquestra√ß√£o do pipeline, executando a extra√ß√£o de dados e o acionamento do job Glue.|
|üß© AWS Glue            | Servi√ßo AWS |Servi√ßo central de ETL, respons√°vel pela transforma√ß√£o e cataloga√ß√£o dos dados.|
|ü™£ Amazon S3           | Servi√ßo AWS |Data Lake para armazenamento dos dados nas camadas raw e refined.|
|üîç Amazon Athena       | Servi√ßo AWS |Servi√ßo de consulta interativa para an√°lise dos dados refinados via SQL.|
|üåâ AWS EventBridge     | Servi√ßo AWS |Agendamento da extra√ß√£o de dados e gatilho para o in√≠cio do ETL.|
---

## üß± Arquitetura da Solu√ß√£o
O pipeline foi desenhado para ser robusto, escal√°vel e de baixo custo, operando de forma totalmente serverless.Abaixo, um diagrama visual do fluxo de dados:

![alt text](docs/imgs/api_fase2.jpg) 

O fluxo de dados ocorre da seguinte maneira:

1. **üìÖ Agendamento:** Uma regra no **Amazon EventBridge** aciona a fun√ß√£o Lambda de extra√ß√£o todos os dias √∫teis √†s 17h.
2. **üì• Extra√ß√£o (Camada Raw):** A fun√ß√£o **Lambda** `lambda-extract-bovespa` executa um script que extrai os dados do preg√£o da B3. Os dados brutos s√£o salvos no Amazon S3, na camada `raw-zone`, em formato Parquet e particionados por data (`/ano/m√™s/dia`).
3. **üîî Gatilho do ETL:** A cria√ß√£o de um novo objeto no bucket S3 dispara um evento, capturado por outra regra no **EventBridge**, que por sua vez aciona a fun√ß√£o **Lambda** `lambda-trigger-glue-bovespa`.
4. **‚öôÔ∏è Processamento (Camada Refined):** A Lambda de trigger inicia o **Job do AWS Glue** `glue-refined-zone-bovespa`. Este job l√™ os dados brutos da camada raw-zone, aplica transforma√ß√µes como limpeza, renomea√ß√£o de colunas, c√°lculos e agrega√ß√µes, e salva os dados processados na camada `refined-zone` do S3.
5. **üìö Cataloga√ß√£o (Glue Data Catalog):** Ao final da execu√ß√£o, o job do Glue atualiza o **Data Catalog**, criando e/ou atualizando as parti√ß√µes da tabela de dados refinados.
6. **üìä An√°lise (Athena):** Os dados refinados e catalogados ficam dispon√≠veis para consulta no **Amazon Athena**, permitindo que analistas e cientistas de dados explorem as informa√ß√µes utilizando sintaxe SQL padr√£o.
---

## üöÄ Como Configurar e Executar o Projeto
Para replicar este projeto em sua pr√≥pria conta AWS, siga os passos abaixo.

### Pr√©-requisitos
 - Conta na AWS com permiss√µes para criar recursos (IAM, S3, Lambda, Glue, EventBridge, Athena).
 - AWS CLI configurado em sua m√°quina local.
 - Python 3.13 instalado.
 - Git instalado.
 - Conhecimento b√°sico sobre os servi√ßos AWS mencionados.

### Passos para o Deploy
1. **Clone o Reposit√≥rio:**
```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```

2. **Crie o Bucket S3:**
    - Crie um bucket no Amazon S3 que ser√° usado como Data Lake. Ex: `fiap-ml-tc-fase2-data-SEUNOME`.
    - Dentro do bucket, crie as pastas `raw-zone/` e `refined-zone/`.

3. **Fa√ßa o Deploy dos Recursos:**
    - **Fun√ß√µes Lambda:** Crie duas fun√ß√µes Lambda (`lambda-extract-bovespa e lambda-trigger-glue-bovespa`) e fa√ßa o upload dos respectivos c√≥digos-fonte localizados no diret√≥rio `src/lambda`. Configure as vari√°veis de ambiente e permiss√µes (IAM Roles) necess√°rias.
    - **Job do Glue:** Crie um novo job no AWS Glue (`glue-refined-zone-bovespa`), aponte para o script `glue-refined-zone-bovespa.py` e configure os par√¢metros do job, como o Role do IAM e as bibliotecas adicionais (`awswrangler`).
    - **Regras do EventBridge:**
        1. Navegue at√© os diret√≥rios de CloudFormation:
            - Os templates de CloudFormation est√£o localizados em src/event-bridge/.
        2. Implante os Stacks:
            - Utilize o AWS CLI para criar ou atualizar os stacks do CloudFormation. Exemplo:
            ```bash
            aws cloudformation deploy \
            --template-file src/event-bridge/start-lambda-lambda-extract-bovespa/start-lambda-lambda-extract-bovespa.json \
            --stack-name StartLambdaExtractBovespaStack \
            --capabilities CAPABILITY_NAMED_IAM # Necess√°rio para criar IAM Roles
            ```
            ```bash
            aws cloudformation deploy \
            --template-file src/event-bridge/create-event-raw-file-bovespa/create-event-raw-file-bovespa.json \
            --stack-name CreateEventRawFileBovespaStack \
            --capabilities CAPABILITY_NAMED_IAM
            ```
    *Lembre-se de atualizar os ARNs dos recursos (Lambda e S3) para corresponder aos da sua conta*

4. **Execute o Pipeline:**
    - **Execu√ß√£o Manual**
        - Para iniciar o fluxo, voc√™ pode executar a Lambda `lambda-extract-bovespa` manualmente pela primeira vez ou aguardar o agendamento do EventBridge.
        - Ap√≥s a execu√ß√£o, os dados brutos aparecer√£o na `raw-zone`. Isso ir√° disparar o restante do pipeline automaticamente.
    - **Execu√ß√£o Automatica**
        - **Extra√ß√£o Di√°ria:** O EventBridge inicia a Lambda `lambda-extract-bovespa` agendada para todos os dias √†s 17h.
        - **ETL Autom√°tico:** A cria√ß√£o de novos arquivos Parquet na Raw Zone do S3 (pela Lambda de extra√ß√£o) acionar√° a `lambda-trigger-glue-bovespa`, que por sua vez iniciar√° o job Glue de ETL.

5. **Consulte os Dados no Athena:**
    - Ap√≥s a conclus√£o do job do Glue, navegue at√© o Amazon Athena.
    - Selecione o banco de dados `db_default` (ou o que foi configurado no script).
    - Execute uma consulta na tabela `tbl_refined_bovespa` para visualizar os dados processados.
    ```sql  
    SELECT * FROM "db_default"."tbl_refined_bovespa" LIMIT 10;
    ```

## üìñ Cat√°logo de Dados e Metadados
Os dados processados pelo pipeline s√£o armazenados e catalogados na tabela `tbl_refined_bovespa`. Abaixo est√£o os detalhes do esquema dessa tabela, conforme definido no script do Glue.

### Esquema da Tabela
|Coluna | Tipo de Dado|  Descri√ß√£o|
|----|----|----|
nom_empresa                             | string | Nome da empresa associada √† a√ß√£o.|
qtd_registros                           | bigint | Contagem total de registros de a√ß√µes para a |empresa naquele dia.
qtd_acao                                | bigint | Quantidade de c√≥digos de a√ß√£o distintos para a |empresa.
qtd_tipos_acao                          | bigint | Quantidade de tipos de a√ß√£o distintos (ON, PN, |etc.).
qtd_teorica_acumulada                   | bigint | Soma da quantidade te√≥rica de todas as a√ß√µes da |empresa.
qtd_teorica_max                         | bigint | Quantidade te√≥rica m√°xima entre as a√ß√µes da |empresa.
qtd_teorica_min                         | bigint | Quantidade te√≥rica m√≠nima entre as a√ß√µes da |empresa.
avg_participacao_setor_total            | double | M√©dia de participa√ß√£o da empresa no setor.|
avg_participacao_setor_acumulada_total  | double | M√©dia de participa√ß√£o acumulada da empresa no |setor.
qtd_dias_atraso                         | int | Diferen√ßa em dias entre a data de refer√™ncia e a |data do processamento.
data_ref                                | date | Data de refer√™ncia do preg√£o da B3.|
dth_etl_processamento                   | timesta| mp Data e hora em que o registro foi processado |pelo ETL.

### Chaves de Parti√ß√£o
A tabela √© particionada para otimizar as consultas e o gerenciamento dos dados no S3.

| Chave de Parti√ß√£o | Tipo de Dado| Descri√ß√£o|
|----|----|----|
|year       |int    | Ano da data de refer√™ncia.|
|month      |int    | M√™s da data de refer√™ncia.|
|day        |int    | Dia da data de refer√™ncia.|
|nom_setor  |string | Setor de atua√ß√£o da empresa.|



### üóÇÔ∏è Estrutura de diretorios

O projeto est√° organizado da seguinte forma para facilitar a navega√ß√£o e o entendimento:

``` text
.
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ docs
‚îÇ   ‚îî‚îÄ‚îÄ imgs
‚îÇ       ‚îî‚îÄ‚îÄ api_fase2.jpg
‚îú‚îÄ‚îÄ notebook
‚îÇ   ‚îî‚îÄ‚îÄ notebook_etl_glue.ipynb     # Notebook para explora√ß√£o e an√°lise dos dados.
‚îî‚îÄ‚îÄ src
    ‚îú‚îÄ‚îÄ event-bridge                # Configura√ß√µes das regras do EventBridge (IaC)
    ‚îÇ   ‚îú‚îÄ‚îÄ create-event-raw-file-bovespa.json
    ‚îÇ   ‚îî‚îÄ‚îÄ start-lambda-lambda-extract-bovespa.json
    ‚îú‚îÄ‚îÄ glue                        # Scripts e configura√ß√µes do AWS Glue
    ‚îÇ   ‚îî‚îÄ‚îÄ glue-refined-zone-bovespa
    ‚îÇ       ‚îú‚îÄ‚îÄ glue-refined-zone-bovespa.json
    ‚îÇ       ‚îî‚îÄ‚îÄ glue-refined-zone-bovespa.py
    ‚îî‚îÄ‚îÄ lambda                      # C√≥digo-fonte das fun√ß√µes Lambda
        ‚îú‚îÄ‚îÄ lambda-extract-bovespa
        ‚îÇ   ‚îî‚îÄ‚îÄ lambda_function.py
        ‚îî‚îÄ‚îÄ lambda-trigger-glue-bovespa
            ‚îî‚îÄ‚îÄ lambda_function.py
```
---

## üé• V√≠deo Demonstrativo
Assista ao v√≠deo explicativo do projeto e seu desenvolvimento em funcionamento: https://sssssssssssss

---

## ü§ù Desenvolvedores
Este projeto foi desenvolvido com a colabora√ß√£o dos seguintes membros:
|Nome | RM | Github|
|----|----|----|
|Lucas Felipe de Jesus Machado      | RM364306 | [link](https://github.com/lfjmachado)
|Ant√¥nio Teixeira Santana Neto      | RM364480 | [link](https://github.com/antonioteixeirasn)
|Gabriela Moreno Rocha dos Santos   | RM364538 | [link](https://github.com/gabrielaMSantos)
|Erik Douglas Alves Gomes           | RM364379 | [link](https://github.com/Erik-DAG)
|Leonardo Fernandes Soares          | RM364648 | [link](https://github.com/leferso)

## ‚öñÔ∏è Licen√ßa
Este projeto est√° sob a licen√ßa **MIT**. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.