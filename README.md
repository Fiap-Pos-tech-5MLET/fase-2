# Projeto Tech Chalenge Fase-2
---
## ğŸ“Œ Ãndice

- [ğŸ“ Sobre o Projeto](#-sobre-o-projeto)
- [ğŸ›  Tecnologias e Ferramentas](#-tecnologias-e-ferramentas-utilizadas)
- [ğŸ§± Arquitetura da SoluÃ§Ã£o](#-arquitetura-da-solucao)
- [ğŸš€ Como Configurar e Executar o Projeto](#como-Configurar-e-Executar-o-Projeto)
- [ğŸ“– CatÃ¡logo de Dados e Metadados](#CatÃ¡logo-de-Dados-e-Metadados)
- [ğŸ—‚ï¸ Estrutura de diretorios](#Estrutura-de-diretorios)
- [ğŸ¥ VÃ­deo Demonstrativo](#-vÃ­deo-demonstrativo)
- [ğŸ¤ Desenvolvedores](#-desenvolvedores)
- [âš–ï¸ LicenÃ§a](#-LicenÃ§a)
---


## ğŸ“ Sobre o Projeto
Este repositÃ³rio contÃ©m a implementaÃ§Ã£o do `Tech Challenge Fase 2 da PÃ³s-GraduaÃ§Ã£o em Machine Learning`, focado na construÃ§Ã£o de um pipeline de dados completo para ingestÃ£o, processamento e anÃ¡lise de dados do pregÃ£o da **B3 (Bovespa)**. A arquitetura Ã© totalmente serverless, utilizando serviÃ§os AWS como `S3`, `Glue`, `Lambda` e `Athena`, seguindo as melhores prÃ¡ticas de Big Data.

O projeto aborda o desafio de extrair dados financeiros de uma fonte externa, transformÃ¡-los em um formato otimizado para anÃ¡lise e disponibilizÃ¡-los para consultas eficientes, garantindo escalabilidade, resiliÃªncia e custo-benefÃ­cio.

### âœ¨ Funcionalidades e Requisitos Implementados
O pipeline de dados foi desenvolvido para atender aos seguintes requisitos obrigatÃ³rios:

- **ExtraÃ§Ã£o de Dados (Scraping):** Realiza o scraping de dados do pregÃ£o do site oficial da B3.

- **IngestÃ£o na Camada Raw:** Os dados brutos sÃ£o ingeridos no Amazon S3 em formato Parquet, com particionamento diÃ¡rio para otimizaÃ§Ã£o de consultas.

- **OrquestraÃ§Ã£o com Lambda:** Um evento no S3 (ao adicionar novos dados brutos) aciona uma funÃ§Ã£o AWS Lambda.

- **Disparo de Job ETL (Glue):** A funÃ§Ã£o Lambda (desenvolvida em Python) Ã© responsÃ¡vel por iniciar um job de ETL (Extract, Transform, Load) no AWS Glue.

    - **TransformaÃ§Ãµes no AWS Glue:** O job Glue, configurado visualmente, executa as seguintes transformaÃ§Ãµes obrigatÃ³rias:

        - **Agrupamento e SumarizaÃ§Ã£o:** Realiza agrupamentos numÃ©ricos com sumarizaÃ§Ã£o, contagem ou soma.

        - **RenomeaÃ§Ã£o de Colunas:** Renomeia duas colunas existentes, alÃ©m das colunas de agrupamento.

        - **CÃ¡lculo com Datas:** Executa um cÃ¡lculo envolvendo campos de data (ex: duraÃ§Ã£o, comparaÃ§Ã£o, diferenÃ§a entre datas).

    - **Armazenamento na Camada Refined:** Os dados processados e refinados pelo job Glue sÃ£o salvos no S3 em formato **Parquet**, em uma pasta `refined`, particionados por data e pelo nome/abreviaÃ§Ã£o da aÃ§Ã£o do pregÃ£o.

    - **CatalogaÃ§Ã£o AutomÃ¡tica (Glue Catalog):** O job Glue cataloga automaticamente os dados no AWS Glue Data Catalog, criando uma tabela no banco de dados padrÃ£o.

- **Disponibilidade no Athena:** Os dados refinados estÃ£o disponÃ­veis e legÃ­veis para consultas no Amazon Athena.

## ğŸ›  Tecnologias e Ferramentas
|Ferramenta| Categoria| UtilizaÃ§Ã£o no Projeto|
|----------|----------|----------|
|ğŸ Python 3.13         | Linguagem de ProgramaÃ§Ã£o |Linguagem principal para as funÃ§Ãµes Lambda e o script PySpark.|
|âœ¨ PySpark Framework   | Framework de Processamento de Dados |utilizado no AWS Glue para processamento distribuÃ­do dos dados.|
|ğŸ‘ AWS Lambda          | ServiÃ§o AWS |OrquestraÃ§Ã£o do pipeline, executando a extraÃ§Ã£o de dados e o acionamento do job Glue.|
|ğŸ§© AWS Glue            | ServiÃ§o AWS |ServiÃ§o central de ETL, responsÃ¡vel pela transformaÃ§Ã£o e catalogaÃ§Ã£o dos dados.|
|ğŸª£ Amazon S3           | ServiÃ§o AWS |Data Lake para armazenamento dos dados nas camadas raw e refined.|
|ğŸ” Amazon Athena       | ServiÃ§o AWS |ServiÃ§o de consulta interativa para anÃ¡lise dos dados refinados via SQL.|
|ğŸŒ‰ AWS EventBridge     | ServiÃ§o AWS |Agendamento da extraÃ§Ã£o de dados e gatilho para o inÃ­cio do ETL.|
---

## ğŸ§± Arquitetura da SoluÃ§Ã£o
O pipeline foi desenhado para ser robusto, escalÃ¡vel e de baixo custo, operando de forma totalmente serverless.Abaixo, um diagrama visual do fluxo de dados:

![alt text](docs/imgs/api_fase2.jpg) 

O fluxo de dados ocorre da seguinte maneira:

1. **ğŸ“… Agendamento:** Uma regra no **Amazon EventBridge** aciona a funÃ§Ã£o Lambda de extraÃ§Ã£o todos os dias Ãºteis Ã s 17h.
2. **ğŸ“¥ ExtraÃ§Ã£o (Camada Raw):** A funÃ§Ã£o **Lambda** `lambda-extract-bovespa` executa um script que extrai os dados do pregÃ£o da B3. Os dados brutos sÃ£o salvos no Amazon S3, na camada `raw-zone`, em formato Parquet e particionados por data (`/ano/mÃªs/dia`).
3. **ğŸ”” Gatilho do ETL:** A criaÃ§Ã£o de um novo objeto no bucket S3 dispara um evento, capturado por outra regra no **EventBridge**, que por sua vez aciona a funÃ§Ã£o **Lambda** `lambda-trigger-glue-bovespa`.
4. **âš™ï¸ Processamento (Camada Refined):** A Lambda de trigger inicia o **Job do AWS Glue** `glue-refined-zone-bovespa`. Este job lÃª os dados brutos da camada raw-zone, aplica transformaÃ§Ãµes como limpeza, renomeaÃ§Ã£o de colunas, cÃ¡lculos e agregaÃ§Ãµes, e salva os dados processados na camada `refined-zone` do S3.
5. **ğŸ“š CatalogaÃ§Ã£o (Glue Data Catalog):** Ao final da execuÃ§Ã£o, o job do Glue atualiza o **Data Catalog**, criando e/ou atualizando as partiÃ§Ãµes da tabela de dados refinados.
6. **ğŸ“Š AnÃ¡lise (Athena):** Os dados refinados e catalogados ficam disponÃ­veis para consulta no **Amazon Athena**, permitindo que analistas e cientistas de dados explorem as informaÃ§Ãµes utilizando sintaxe SQL padrÃ£o.
---

## ğŸš€ Como Configurar e Executar o Projeto
Para replicar este projeto em sua prÃ³pria conta AWS, siga os passos abaixo.

### PrÃ©-requisitos
 - Conta na AWS com permissÃµes para criar recursos (IAM, S3, Lambda, Glue, EventBridge, Athena).
 - AWS CLI configurado em sua mÃ¡quina local.
 - Python 3.13 instalado.
 - Git instalado.
 - Conhecimento bÃ¡sico sobre os serviÃ§os AWS mencionados.

### Passos para o Deploy
1. **Clone o RepositÃ³rio:**
```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
```

2. **Crie o Bucket S3:**
    - Crie um bucket no Amazon S3 que serÃ¡ usado como Data Lake. Ex: `fiap-ml-tc-fase2-data-SEUNOME`.
    - Dentro do bucket, crie as pastas `raw-zone/` e `refined-zone/`.

3. **FaÃ§a o Deploy dos Recursos:**
    - **FunÃ§Ãµes Lambda:** Crie duas funÃ§Ãµes Lambda (`lambda-extract-bovespa e lambda-trigger-glue-bovespa`) e faÃ§a o upload dos respectivos cÃ³digos-fonte localizados no diretÃ³rio `src/lambda`. Configure as variÃ¡veis de ambiente e permissÃµes (IAM Roles) necessÃ¡rias.
    - **Job do Glue:** Crie um novo job no AWS Glue (`glue-refined-zone-bovespa`), aponte para o script `glue-refined-zone-bovespa.py` e configure os parÃ¢metros do job, como o Role do IAM e as bibliotecas adicionais (`awswrangler`).
    - **Regras do EventBridge:**
        1. Navegue atÃ© os diretÃ³rios de CloudFormation:
            - Os templates de CloudFormation estÃ£o localizados em src/event-bridge/.
        2. Implante os Stacks:
            - Utilize o AWS CLI para criar ou atualizar os stacks do CloudFormation. Exemplo:
            ```bash
            aws cloudformation deploy \
            --template-file src/event-bridge/start-lambda-lambda-extract-bovespa/start-lambda-lambda-extract-bovespa.json \
            --stack-name StartLambdaExtractBovespaStack \
            --capabilities CAPABILITY_NAMED_IAM # NecessÃ¡rio para criar IAM Roles
            ```
            ```bash
            aws cloudformation deploy \
            --template-file src/event-bridge/create-event-raw-file-bovespa/create-event-raw-file-bovespa.json \
            --stack-name CreateEventRawFileBovespaStack \
            --capabilities CAPABILITY_NAMED_IAM
            ```
    *Lembre-se de atualizar os ARNs dos recursos (Lambda e S3) para corresponder aos da sua conta*

4. **Execute o Pipeline:**
    - **ExecuÃ§Ã£o Manual**
        - Para iniciar o fluxo, vocÃª pode executar a Lambda `lambda-extract-bovespa` manualmente pela primeira vez ou aguardar o agendamento do EventBridge.
        - ApÃ³s a execuÃ§Ã£o, os dados brutos aparecerÃ£o na `raw-zone`. Isso irÃ¡ disparar o restante do pipeline automaticamente.
    - **ExecuÃ§Ã£o Automatica**
        - **ExtraÃ§Ã£o DiÃ¡ria:** O EventBridge inicia a Lambda `lambda-extract-bovespa` agendada para todos os dias Ã s 17h.
        - **ETL AutomÃ¡tico:** A criaÃ§Ã£o de novos arquivos Parquet na Raw Zone do S3 (pela Lambda de extraÃ§Ã£o) acionarÃ¡ a `lambda-trigger-glue-bovespa`, que por sua vez iniciarÃ¡ o job Glue de ETL.

5. **Consulte os Dados no Athena:**
    - ApÃ³s a conclusÃ£o do job do Glue, navegue atÃ© o Amazon Athena.
    - Selecione o banco de dados `db_default` (ou o que foi configurado no script).
    - Execute uma consulta na tabela `tbl_refined_bovespa` para visualizar os dados processados.
    ```sql  
    SELECT * FROM "db_default"."tbl_refined_bovespa" LIMIT 10;
    ```

## ğŸ“– CatÃ¡logo de Dados e Metadados
Os dados processados pelo pipeline sÃ£o armazenados e catalogados na tabela `tbl_refined_bovespa`. Abaixo estÃ£o os detalhes do esquema dessa tabela, conforme definido no script do Glue.

### Esquema da Tabela
|Coluna | Tipo de Dado|  DescriÃ§Ã£o|
|----|----|----|
nom_empresa                             | string | Nome da empresa associada Ã  aÃ§Ã£o.|
qtd_registros                           | bigint | Contagem total de registros de aÃ§Ãµes para a |empresa naquele dia.
qtd_acao                                | bigint | Quantidade de cÃ³digos de aÃ§Ã£o distintos para a |empresa.
qtd_tipos_acao                          | bigint | Quantidade de tipos de aÃ§Ã£o distintos (ON, PN, |etc.).
qtd_teorica_acumulada                   | bigint | Soma da quantidade teÃ³rica de todas as aÃ§Ãµes da |empresa.
qtd_teorica_max                         | bigint | Quantidade teÃ³rica mÃ¡xima entre as aÃ§Ãµes da |empresa.
qtd_teorica_min                         | bigint | Quantidade teÃ³rica mÃ­nima entre as aÃ§Ãµes da |empresa.
avg_participacao_setor_total            | double | MÃ©dia de participaÃ§Ã£o da empresa no setor.|
avg_participacao_setor_acumulada_total  | double | MÃ©dia de participaÃ§Ã£o acumulada da empresa no |setor.
qtd_dias_atraso                         | int | DiferenÃ§a em dias entre a data de referÃªncia e a |data do processamento.
data_ref                                | date | Data de referÃªncia do pregÃ£o da B3.|
dth_etl_processamento                   | timesta| mp Data e hora em que o registro foi processado |pelo ETL.

### Chaves de PartiÃ§Ã£o
A tabela Ã© particionada para otimizar as consultas e o gerenciamento dos dados no S3.

| Chave de PartiÃ§Ã£o | Tipo de Dado| DescriÃ§Ã£o|
|----|----|----|
|year       |int    | Ano da data de referÃªncia.|
|month      |int    | MÃªs da data de referÃªncia.|
|day        |int    | Dia da data de referÃªncia.|
|nom_setor  |string | Setor de atuaÃ§Ã£o da empresa.|



### ğŸ—‚ï¸ Estrutura de diretorios

O projeto estÃ¡ organizado da seguinte forma para facilitar a navegaÃ§Ã£o e o entendimento:

``` text
.
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ docs
â”‚   â””â”€â”€ imgs
â”‚       â””â”€â”€ api_fase2.jpg
â”œâ”€â”€ notebook
â”‚   â””â”€â”€ notebook_etl_glue.ipynb     # Notebook para exploraÃ§Ã£o e anÃ¡lise dos dados.
â””â”€â”€ src
    â”œâ”€â”€ event-bridge                # ConfiguraÃ§Ãµes das regras do EventBridge (IaC)
    â”‚   â”œâ”€â”€ create-event-raw-file-bovespa.json
    â”‚   â””â”€â”€ start-lambda-lambda-extract-bovespa.json
    â”œâ”€â”€ glue                        # Scripts e configuraÃ§Ãµes do AWS Glue
    â”‚   â””â”€â”€ glue-refined-zone-bovespa
    â”‚       â”œâ”€â”€ glue-refined-zone-bovespa.json
    â”‚       â””â”€â”€ glue-refined-zone-bovespa.py
    â””â”€â”€ lambda                      # CÃ³digo-fonte das funÃ§Ãµes Lambda
        â”œâ”€â”€ lambda-extract-bovespa
        â”‚   â””â”€â”€ lambda_function.py
        â””â”€â”€ lambda-trigger-glue-bovespa
            â””â”€â”€ lambda_function.py
```
---

## ğŸ¥ VÃ­deo Demonstrativo
Assista ao vÃ­deo explicativo do projeto e seu desenvolvimento em funcionamento: https://sssssssssssss

---

## ğŸ¤ Desenvolvedores
Este projeto foi desenvolvido com a colaboraÃ§Ã£o dos seguintes membros:
|Nome | RM | Github|
|----|----|----|
|Lucas Felipe de Jesus Machado      | RM364306 | [link](https://github.com/lfjmachado)
|AntÃ´nio Teixeira Santana Neto      | RM364480 | [link](https://github.com/antonioteixeirasn)
|Gabriela Moreno Rocha dos Santos   | RM364538 | [link](https://github.com/gabrielaMSantos)
|Erik Douglas Alves Gomes           | RM364379 | [link](https://github.com/Erik-DAG)
|Leonardo Fernandes Soares          | RM364648 | [link](https://github.com/leferso)

## âš–ï¸ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a **MIT**. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.